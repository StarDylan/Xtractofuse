{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point cloud 884\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Xtractofuse/lib/python3.10/site-packages/pythreejs/traits.py:257: UserWarning: 64-bit data types not supported for WebGL data, casting to 32-bit.\n",
      "  warnings.warn('64-bit data types not supported for WebGL '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "np.float, np.int = np.float64, np.int_\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from pythreejs import *\n",
    "from IPython.display import display\n",
    "\n",
    "DEPTH_WIDTH = 256\n",
    "DEPTH_HEIGHT = 192\n",
    "MAX_DEPTH = 20.0\n",
    "path = 'Data'\n",
    "confidence = 2\n",
    "every = 5\n",
    "\n",
    "def extract_frames(video_path, frame_dir):\n",
    "    os.makedirs(frame_dir, exist_ok=True)\n",
    "    \n",
    "    subprocess.run([\n",
    "        'ffmpeg', '-i', video_path, '-vsync', 'vfr', '-q:v', '1', '-start_number', '0',\n",
    "        os.path.join(frame_dir, '%06d.png')\n",
    "    ])\n",
    "\n",
    "\n",
    "def quaternion_to_rotation_matrix(quaternion):\n",
    "    qx, qy, qz, qw = quaternion\n",
    "    return np.array([\n",
    "        [1 - 2 * (qy**2 + qz**2), 2 * (qx * qy - qz * qw), 2 * (qx * qz + qy * qw)],\n",
    "        [2 * (qx * qy + qz * qw), 1 - 2 * (qx**2 + qz**2), 2 * (qy * qz - qx * qw)],\n",
    "        [2 * (qx * qz - qy * qw), 2 * (qy * qz + qx * qw), 1 - 2 * (qx**2 + qy**2)]\n",
    "    ])\n",
    "\n",
    "def get_intrinsics(data):\n",
    "    fx = data['intrinsics'][0, 0]\n",
    "    fy = data['intrinsics'][1, 1]\n",
    "    cx = data['intrinsics'][0, 2]\n",
    "    cy = data['intrinsics'][1, 2]\n",
    "    return np.array([[fx * DEPTH_WIDTH / 1920, 0, cx * DEPTH_WIDTH / 1920],\n",
    "                     [0, fy * DEPTH_HEIGHT / 1440, cy * DEPTH_HEIGHT / 1440],\n",
    "                     [0, 0, 1]])\n",
    "\n",
    "def create_point_cloud(rgbd, intrinsics, T_CW):\n",
    "    rgb, depth = rgbd\n",
    "    fx, fy = intrinsics[0, 0], intrinsics[1, 1]\n",
    "    cx, cy = intrinsics[0, 2], intrinsics[1, 2]\n",
    "\n",
    "    points, colors = [], []\n",
    "    for v in range(depth.shape[0]):\n",
    "        for u in range(depth.shape[1]):\n",
    "            z = depth[v, u]\n",
    "            if z > 0 and z < MAX_DEPTH:\n",
    "                x = (u - cx) * z / fx\n",
    "                y = (v - cy) * z / fy\n",
    "                point_world = T_CW[:3, :3] @ np.array([x, y, z]) + T_CW[:3, 3]\n",
    "                points.append(point_world)\n",
    "                colors.append(rgb[v, u] / 255.0)\n",
    "    return np.array(points), np.array(colors)\n",
    "\n",
    "def accumulate_point_cloud(pc, rgbd, intrinsics, T_CW):\n",
    "    points, colors = create_point_cloud(rgbd, intrinsics, T_CW)\n",
    "    pc[0].extend(points)\n",
    "    pc[1].extend(colors)\n",
    "\n",
    "\n",
    "def visualize_point_cloud(points, colors):\n",
    "    # Convert colors to the 0-1 range for pythreejs compatibility\n",
    "    colors = np.clip(colors, 0, 1)\n",
    "    \n",
    "    # Create a BufferGeometry with the point cloud data\n",
    "    geometry = BufferGeometry(\n",
    "        attributes={\n",
    "            'position': BufferAttribute(points, normalized=False),\n",
    "            'color': BufferAttribute(colors, normalized=False)\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Define the material, use vertex colors for each point\n",
    "    material = PointsMaterial(vertexColors='VertexColors', size=0.05)\n",
    "    point_cloud = Points(geometry=geometry, material=material)\n",
    "\n",
    "    # Set up a scene\n",
    "    camera = PerspectiveCamera(position=[3, 3, 3], fov=75, children=[DirectionalLight(color='white', position=[0, 0, 1], intensity=0.5)])\n",
    "    scene = Scene(children=[point_cloud, camera, AmbientLight(color='#777777')])\n",
    "    \n",
    "    # Display the scene\n",
    "    renderer = Renderer(camera=camera, scene=scene, controls=[OrbitControls(controlling=camera)], width=800, height=600)\n",
    "    display(renderer)\n",
    "\n",
    "def process_point_clouds(data):\n",
    "    intrinsics = get_intrinsics(data)\n",
    "    pc = ([], [])\n",
    "    video_path = os.path.join(path, 'rgb.mp4')\n",
    "    frame_dir = os.path.join(path, 'frames')\n",
    "    \n",
    "    if not os.path.exists(frame_dir):\n",
    "        extract_frames(video_path, frame_dir)\n",
    "\n",
    "    for i, T_WC in enumerate(data['poses']):\n",
    "        if i % every != 0:\n",
    "            continue\n",
    "        print(f\"Point cloud {i}\", end=\"\\r\")\n",
    "        T_CW = np.linalg.inv(T_WC)\n",
    "        confidence = np.array(Image.open(os.path.join(path, 'confidence', f'{i:06}.png')))\n",
    "        depth_path = data['depth_frames'][i]\n",
    "        depth_m = np.array(Image.open(depth_path)).astype(np.float32) / 1000.0\n",
    "        depth_m[confidence < confidence] = 0.0\n",
    "        \n",
    "        rgb_frame_path = os.path.join(frame_dir, f'{i:06}.png')\n",
    "        rgb_frame = np.array(Image.open(rgb_frame_path))\n",
    "        rgbd = (np.array(Image.fromarray(rgb_frame).resize((DEPTH_WIDTH, DEPTH_HEIGHT))), depth_m)\n",
    "        \n",
    "        accumulate_point_cloud(pc, rgbd, intrinsics, T_WC)\n",
    "\n",
    "    points, colors = np.array(pc[0]), np.array(pc[1])\n",
    "    visualize_point_cloud(points, colors)\n",
    "\n",
    "\n",
    "intrinsics = np.loadtxt(os.path.join(path, 'camera_matrix.csv'), delimiter=',')\n",
    "odometry = np.loadtxt(os.path.join(path, 'odometry.csv'), delimiter=',', skiprows=1)\n",
    "poses = []\n",
    "\n",
    "for line in odometry:\n",
    "    position, quaternion = line[2:5], line[5:]\n",
    "    T_WC = np.eye(4)\n",
    "    T_WC[:3, :3] = quaternion_to_rotation_matrix(quaternion)\n",
    "    T_WC[:3, 3] = position\n",
    "    poses.append(T_WC)\n",
    "\n",
    "depth_dir = os.path.join(path, 'depth')\n",
    "depth_frames = [os.path.join(depth_dir, p) for p in sorted(os.listdir(depth_dir))]\n",
    "\n",
    "process_point_clouds({'poses': poses, 'intrinsics': intrinsics, 'depth_frames': depth_frames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Xtractofuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
